{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.classification import Accuracy, F1, AUROC\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our images in the right folders so we can use ImageFolder\n",
    "\n",
    "project_path = os.getcwd().replace('/notebooks', '')\n",
    "csv_path = project_path + '/data/HAM10000_metadata'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    source = project_path + '/data/images/' + row['image_id'] + '.jpg'\n",
    "    destination = project_path + '/data/images/' + row['dx'] + '/' + row['image_id'] + '.jpg'\n",
    "    destination_folder = project_path + '/data/images/' + row['dx']\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.mkdir(destination_folder)\n",
    "    if os.path.exists(source):\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2212\n"
     ]
    }
   ],
   "source": [
    "# Setting up our dataloaders\n",
    "\n",
    "val_size = 0.1\n",
    "test_size = 0.8\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.CenterCrop((448, 576))\n",
    "])\n",
    "\n",
    "ds = torchvision.datasets.ImageFolder(project_path + '/data/images2', transform=transform)\n",
    "n_val = int(val_size * len(ds))\n",
    "n_test = int(test_size * len(ds))\n",
    "n_train = len(ds) - (n_val + n_test)\n",
    "train_ds, val_ds, test_ds = random_split(ds, (n_train, n_val, n_test))\n",
    "print(len(ds))\n",
    "\n",
    "class_weights = [30.6, 19.5, 9.1, 87.1, 9.0, 1.5, 70.5]\n",
    "train_ds_weights = [class_weights[label] for image, label in train_ds]\n",
    "train_loader = DataLoader(train_ds, batch_size=11, num_workers=6, shuffle=True)\n",
    "weighted_train_loader = DataLoader(train_ds, batch_size=11, num_workers=6, sampler=WeightedRandomSampler(train_ds_weights, len(train_ds), replacement=True))\n",
    "val_loader = DataLoader(val_ds, batch_size=11, num_workers=6, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=11, num_workers=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture specification\n",
    "\n",
    "class Baseline(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.accuracy = Accuracy()\n",
    "        self.f1 = F1()\n",
    "\n",
    "        self.NN = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*18*14, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.NN(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "        return {\n",
    "           'optimizer': optimizer,\n",
    "           'lr_scheduler': scheduler,\n",
    "           'monitor': 'val_loss'\n",
    "        }\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y_true = train_batch\n",
    "        y_pred = self.NN(x)\n",
    "        loss = F.cross_entropy(y_pred, y_true.view(-1))\n",
    "        self.log('train_loss', loss, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y_true = val_batch\n",
    "        y_pred = self.NN(x)\n",
    "        loss = F.cross_entropy(y_pred, y_true.view(-1))\n",
    "        acc = self.accuracy(torch.argmax(y_pred, dim=1), y_true.view(-1))\n",
    "        f1 = self.f1(torch.argmax(y_pred, dim=1), y_true.view(-1))\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('accuracy', acc, prog_bar=True)\n",
    "        self.log('f1', f1, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# Init model and trainer\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"Baseline\", version='test')\n",
    "callbacks = [\n",
    "    EarlyStopping('val_loss', patience=5),\n",
    "    LearningRateMonitor(logging_interval='step'),\n",
    "    ]\n",
    "trainer = pl.Trainer(gpus=1, auto_lr_find=False, max_epochs=25, logger=logger, callbacks=callbacks)\n",
    "model = Baseline(lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | accuracy | Accuracy   | 0     \n",
      "1 | f1       | F1         | 0     \n",
      "2 | NN       | Sequential | 1.7 M \n",
      "----------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.731     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 42/42 [00:03<00:00, 10.65it/s, loss=0.692, v_num=test, val_loss=0.697, accuracy=0.466, f1=0.466]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "debug_ds_weights = [1.0 if (i==0 or i==1 or i==2) else 0.0 for i in range(len(train_ds))]\n",
    "debug_loader = DataLoader(train_ds, batch_size=10, num_workers=6, sampler=WeightedRandomSampler(debug_ds_weights, len(train_ds), replacement=True))\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "tensor([[0.0982, 0.0202]])\n",
      "tensor([[0.0979, 0.0207]])\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0][1])\n",
    "print(train_ds[1][1])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(model(train_ds[0][0].unsqueeze(0)))\n",
    "    print(model(train_ds[1][0].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "val_ds_weights = [class_weights[label] for image, label in val_ds]\n",
    "weighted_val_loader = DataLoader(val_ds, batch_size=25, num_workers=6, sampler=WeightedRandomSampler(val_ds_weights, len(val_ds), replacement=True))\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for inputs, labels in weighted_val_loader:\n",
    "                logits = model(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(logits), 1))[1].cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')\n",
    "classes = [1, 2]\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix)*7, index = [i for i in classes], columns = [i for i in classes])\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd7180015afb5c2b39819f98dde8a9af643fe9afa196f2eb6eaf1e4a6c9ffccd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}